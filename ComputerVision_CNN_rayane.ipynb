{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "865976c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4d96c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbookpro16/opt/anaconda3/lib/python3.8/site-packages/h5py/__init__.py:70: UserWarning: h5py is running against HDF5 1.10.4 when it was built against 1.8.4, this may cause problems\n",
      "  _warn((\"h5py is running against HDF5 {0} when it was built against {1}, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25 images belonging to 25 classes.\n",
      "Found 25 images belonging to 25 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'0': 0,\n",
       " '1': 1,\n",
       " '10': 2,\n",
       " '11': 3,\n",
       " '12': 4,\n",
       " '13': 5,\n",
       " '14': 6,\n",
       " '15': 7,\n",
       " '17': 8,\n",
       " '19': 9,\n",
       " '2': 10,\n",
       " '20': 11,\n",
       " '21': 12,\n",
       " '22': 13,\n",
       " '23': 14,\n",
       " '24': 15,\n",
       " '25': 16,\n",
       " '27': 17,\n",
       " '3': 18,\n",
       " '4': 19,\n",
       " '5': 20,\n",
       " '6': 21,\n",
       " '7': 22,\n",
       " '8': 23,\n",
       " '9': 24}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Deep Learning CNN model to recognize face\n",
    " \n",
    "# Specifying the folder where images are present\n",
    "TrainingImagePath='dataset'\n",
    " \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    " \n",
    "# Defining pre-processing transformations on raw images of training data\n",
    "# These hyper parameters helps to generate slightly twisted versions\n",
    "# of the original image, which leads to a better model, since it learns\n",
    "# on the good and bad mix of images\n",
    "train_datagen = ImageDataGenerator(\n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True)\n",
    " \n",
    "# Defining pre-processing transformations on raw images of testing data\n",
    "# No transformations are done on the testing images\n",
    "test_datagen = ImageDataGenerator()\n",
    " \n",
    "# Generating the Training Data\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "        TrainingImagePath,\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    " \n",
    " \n",
    "# Generating the Testing Data\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "        TrainingImagePath,\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    " \n",
    "# Printing class labels for each face\n",
    "test_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a74b8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping of Face and its ID {0: '0', 1: '1', 2: '10', 3: '11', 4: '12', 5: '13', 6: '14', 7: '15', 8: '17', 9: '19', 10: '2', 11: '20', 12: '21', 13: '22', 14: '23', 15: '24', 16: '25', 17: '27', 18: '3', 19: '4', 20: '5', 21: '6', 22: '7', 23: '8', 24: '9'}\n",
      "\n",
      " The Number of output neurons:  25\n"
     ]
    }
   ],
   "source": [
    "'''############ Creating lookup table for all faces ############'''\n",
    "# class_indices have the numeric tag for each face\n",
    "TrainClasses=training_set.class_indices\n",
    " \n",
    "# Storing the face and the numeric tag for future reference\n",
    "ResultMap={}\n",
    "for faceValue,faceName in zip(TrainClasses.values(),TrainClasses.keys()):\n",
    "    ResultMap[faceValue]=faceName\n",
    " \n",
    "# Saving the face map for future reference\n",
    "import pickle\n",
    "with open(\"ResultsMap.pkl\", 'wb') as fileWriteStream:\n",
    "    pickle.dump(ResultMap, fileWriteStream)\n",
    " \n",
    "# The model will give answer as a numeric tag\n",
    "# This mapping will help to get the corresponding face name for it\n",
    "print(\"Mapping of Face and its ID\",ResultMap)\n",
    " \n",
    "# The number of neurons for the output layer is equal to the number of faces\n",
    "OutputNeurons=len(ResultMap)\n",
    "print('\\n The Number of output neurons: ', OutputNeurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6949a496",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-ee2f63fb21b0>:43: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  classifier.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1/1 [==============================] - ETA: 0s - loss: 134.1236 - accuracy: 0.0400WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10 batches). You may need to use the repeat() function when building your dataset.\n",
      "1/1 [==============================] - 5s 5s/step - loss: 134.1236 - accuracy: 0.0400 - val_loss: 231.9003 - val_accuracy: 0.0400\n",
      "Epoch 2/15\n",
      "1/1 [==============================] - 1s 1s/step - loss: 223.2693 - accuracy: 0.0400\n",
      "Epoch 3/15\n",
      "1/1 [==============================] - 1s 1s/step - loss: 90.6913 - accuracy: 0.0000e+00\n",
      "Epoch 4/15\n",
      "1/1 [==============================] - 1s 1s/step - loss: 49.7364 - accuracy: 0.0400\n",
      "Epoch 5/15\n",
      "1/1 [==============================] - 1s 1s/step - loss: 13.8539 - accuracy: 0.0400\n",
      "Epoch 6/15\n",
      "1/1 [==============================] - 1s 1s/step - loss: 7.8880 - accuracy: 0.0400\n",
      "Epoch 7/15\n",
      "1/1 [==============================] - 1s 1s/step - loss: 5.9806 - accuracy: 0.1200\n",
      "Epoch 8/15\n",
      "1/1 [==============================] - 1s 1s/step - loss: 4.8545 - accuracy: 0.1200\n",
      "Epoch 9/15\n",
      "1/1 [==============================] - 1s 1s/step - loss: 4.1655 - accuracy: 0.0800\n",
      "Epoch 10/15\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.5258 - accuracy: 0.2800\n",
      "Epoch 11/15\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.5722 - accuracy: 0.2800\n",
      "Epoch 12/15\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.1058 - accuracy: 0.4400\n",
      "Epoch 13/15\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.9502 - accuracy: 0.4800\n",
      "Epoch 14/15\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.7973 - accuracy: 0.5200\n",
      "Epoch 15/15\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.6446 - accuracy: 0.5200\n",
      "###### Total Time Taken:  0 Minutes ######\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPool2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    " \n",
    "'''Initializing the Convolutional Neural Network'''\n",
    "classifier= Sequential()\n",
    " \n",
    "''' STEP--1 Convolution\n",
    "# Adding the first layer of CNN\n",
    "# we are using the format (64,64,3) because we are using TensorFlow backend\n",
    "# It means 3 matrix of size (64X64) pixels representing Red, Green and Blue components of pixels\n",
    "'''\n",
    "classifier.add(Convolution2D(32, kernel_size=(5, 5), strides=(1, 1), input_shape=(64,64,3), activation='relu'))\n",
    " \n",
    "'''# STEP--2 MAX Pooling'''\n",
    "classifier.add(MaxPool2D(pool_size=(2,2)))\n",
    " \n",
    "'''############## ADDITIONAL LAYER of CONVOLUTION for better accuracy #################'''\n",
    "classifier.add(Convolution2D(64, kernel_size=(5, 5), strides=(1, 1), activation='relu'))\n",
    " \n",
    "classifier.add(MaxPool2D(pool_size=(2,2)))\n",
    " \n",
    "'''# STEP--3 FLattening'''\n",
    "classifier.add(Flatten())\n",
    " \n",
    "'''# STEP--4 Fully Connected Neural Network'''\n",
    "classifier.add(Dense(64, activation='relu'))\n",
    " \n",
    "classifier.add(Dense(OutputNeurons, activation='softmax'))\n",
    " \n",
    "'''# Compiling the CNN'''\n",
    "#classifier.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "classifier.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics=[\"accuracy\"])\n",
    " \n",
    "###########################################################\n",
    "import time\n",
    "# Measuring the time taken by the model to train\n",
    "StartTime=time.time()\n",
    " \n",
    "# Starting the model training\n",
    "classifier.fit_generator(\n",
    "                    training_set,\n",
    "                    steps_per_epoch=1,\n",
    "                    epochs=15,\n",
    "                    validation_data=test_set,\n",
    "                    validation_steps=10)\n",
    " \n",
    "EndTime=time.time()\n",
    "print(\"###### Total Time Taken: \", round((EndTime-StartTime)/60), 'Minutes ######')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "853824f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5856 frames.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the video\n",
    "video_path = 'dataset_video/Video_Boumediene_Rayane.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Load the Haar cascade classifier for object detection\n",
    "cascade_path = 'haarcascade_frontalface_default.xml'\n",
    "face_cascade = cv2.CascadeClassifier(cascade_path)\n",
    "\n",
    "# Output file path for saving the bounding box predictions\n",
    "output_file = 'bounding_box_rayane.txt'\n",
    "\n",
    "# Open the output file in write mode\n",
    "with open(output_file, 'w') as f:\n",
    "    frame_count = 0\n",
    "\n",
    "    while True:\n",
    "        # Read the next frame from the video\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Perform object detection on the frame using Haar cascade classifier\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "        # Iterate over detected faces and write the bounding box coordinates to the output file in YOLO format\n",
    "        for (x, y, w, h) in faces:\n",
    "            frame_height, frame_width, _ = frame.shape\n",
    "            x_center = (x + x + w) / (2 * frame_width)\n",
    "            y_center = (y + y + h) / (2 * frame_height)\n",
    "            width = w / frame_width\n",
    "            height = h / frame_height\n",
    "\n",
    "            # Write the bounding box coordinates to the output file in YOLO format\n",
    "            line = f'0 {x_center} {y_center} {width} {height}\\n'  # Assuming class index 0\n",
    "            f.write(line)\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    print(f'Processed {frame_count} frames.')\n",
    "\n",
    "# Release the video capture and close the output file\n",
    "cap.release()\n",
    "\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e489d5f8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def calculate_iou(box1, box2):\n",
    "    # Convert YOLO format to (x_min, y_min, x_max, y_max)\n",
    "    box1 = convert_yolo_to_coordinates(box1)\n",
    "    box2 = convert_yolo_to_coordinates(box2)\n",
    "\n",
    "    if box1 is None or box2 is None:\n",
    "        return 0\n",
    "\n",
    "    # Calculate the intersection coordinates\n",
    "    x_min = max(box1[0], box2[0])\n",
    "    y_min = max(box1[1], box2[1])\n",
    "    x_max = min(box1[2], box2[2])\n",
    "    y_max = min(box1[3], box2[3])\n",
    "\n",
    "    # Calculate the intersection area\n",
    "    intersection_area = max(0, x_max - x_min) * max(0, y_max - y_min)\n",
    "\n",
    "    # Calculate the union area\n",
    "    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "    union_area = box1_area + box2_area - intersection_area\n",
    "\n",
    "    # Calculate the IoU\n",
    "    iou = intersection_area / union_area\n",
    "    return iou\n",
    "\n",
    "def convert_yolo_to_coordinates(box):\n",
    "    try:\n",
    "        x, y, w, h = map(float, box)\n",
    "        x_min = (x - w / 2)\n",
    "        y_min = (y - h / 2)\n",
    "        x_max = (x + w / 2)\n",
    "        y_max = (y + h / 2)\n",
    "        return x_min, y_min, x_max, y_max\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "def calculate_f1_score(ground_truth_folder, predicted_file, iou_threshold):\n",
    "    # Read the predicted bounding box coordinates from the file\n",
    "    with open(predicted_file, 'r') as f:\n",
    "        predicted_boxes = [line.strip().split() for line in f.readlines()]\n",
    "\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    false_negatives = 0\n",
    "\n",
    "    for pred_box in predicted_boxes:\n",
    "        max_iou = 0\n",
    "        gt_files = os.listdir(ground_truth_folder)\n",
    "        if len(gt_files) == 0:\n",
    "            continue  # Skip iteration if there are no ground truth files\n",
    "        for file in gt_files:\n",
    "            gt_file = os.path.join(ground_truth_folder, file)\n",
    "            with open(gt_file, 'r') as f:\n",
    "                ground_truth_boxes = [line.strip().split() for line in f.readlines()]\n",
    "            for gt_box in ground_truth_boxes:\n",
    "                if len(gt_box) == 5:\n",
    "                    iou = calculate_iou(pred_box[1:], gt_box[1:])\n",
    "                    if iou > max_iou:\n",
    "                        max_iou = iou\n",
    "        if max_iou >= iou_threshold:\n",
    "            true_positives += 1\n",
    "        else:\n",
    "            false_positives += 1\n",
    "\n",
    "    false_negatives = len(gt_files) - true_positives\n",
    "\n",
    "    if true_positives == 0 and false_positives == 0 and false_negatives == 0:\n",
    "        # Handle the case when there are no true positives, false positives, or false negatives\n",
    "        precision = 0\n",
    "        recall = 0\n",
    "    else:\n",
    "        precision = true_positives / (true_positives + false_positives)\n",
    "        recall = true_positives / (true_positives + false_negatives)\n",
    "\n",
    "    if precision + recall == 0:\n",
    "        f1_score = 0  # Set F1 score to zero if both precision and recall are zero\n",
    "    else:\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    return f1_score\n",
    "\n",
    "ground_truth_folder = 'labels/labelled_frames_Video_Boumediene_Rayane'\n",
    "predicted_file = 'bounding_box_rayane.txt'\n",
    "iou_threshold = 0.5\n",
    "output_file = 'f1_score_result_cnn_rayane.txt'\n",
    "\n",
    "f1_score = calculate_f1_score(ground_truth_folder, predicted_file, iou_threshold)\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "    f.write(f\"F1 Score: {f1_score}\\n\")\n",
    "\n",
    "print(f\"F1 Score saved in {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b641fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "b045dd51e3de9668a64145f82622633418244c231464f197f78fca85e5c45f79"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
